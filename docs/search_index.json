[["index.html", "Inferential Statistics Chapter 1 Point Estimation 1.1 Overview 1.2 Maximum Likelihood Estimation", " Inferential Statistics AbdulHafiz Abba 2024-03-14 Chapter 1 Point Estimation 1.1 Overview Suppose we have an unknown population parameter, such as a population mean \\(\\mu\\) or a population proportion \\(p\\), which we’d like to estimate. For example, suppose we are interested in estimating: \\(p\\): the (unknown) proportion of American college students, 18-24, who have a smartphone \\(\\mu\\): the (unknown) mean number of days it takes Alzheimer’s patients to achieve certain milestones In either case, we can’t possibly survey the entire population. That is, we can’t survey all American college students between the ages of 18 and 24. Nor can we survey all patients with Alzheimer’s disease. So, of course, we take a random sample from the population and use the resulting data to estimate the value of the population parameter. However, we want the estimate to be “good” in some way. In this lesson, we’ll learn two methods, namely the method of maximum likelihood and the method of moments, for deriving formulas for “good” point estimates for population parameters. We’ll also learn one way of assessing whether a point estimate is “good.” We’ll do that by defining what it means for an estimate to be unbiased. 1.1.1 Definitions We’ll start the lesson with some formal definitions. In doing so, recall that we denote the \\(n\\) random variables arising from a random sample as subscripted uppercase letters: \\(X_1, X_2, \\ldots, X_n\\). The corresponding observed values of a specific random sample are then denoted as subscripted lowercase letters: \\(x_1, x_2, \\ldots, x_n\\). Parameter Space The range of possible values of the parameter \\(\\theta\\) is called the parameter space \\(\\Omega\\) (the Greek letter “omega”). For example, if \\(\\mu\\) denotes the mean grade point average of all college students, then the parameter space (assuming a 4-point grading scale) is: \\[ \\Omega = \\{ \\mu : 0 \\leq \\mu \\leq 4 \\} \\] And, if \\(p\\) denotes the proportion of students who smoke cigarettes, then the parameter space is: \\[ \\Omega = \\{ p : 0 \\leq p \\leq 1 \\} \\] Point Estimator The function of \\(X_1, X_2, \\ldots, X_n\\), that is, the statistic \\(u = (X_1, X_2, \\ldots, X_n)\\) used to estimate \\(\\theta\\) is called a point estimator of \\(\\theta\\). For example, the function: \\[ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\] is a point estimator of the population mean \\(\\mu\\). The function: \\[ \\hat{p} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\] (where \\(X_i = 0\\) or 1) is a point estimator of the population proportion \\(p\\). And, the function: \\[ S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2 \\] is a point estimator of the population variance \\(\\sigma^2\\). Point Estimate The function \\(u(x_1, x_2, \\ldots, x_n)\\) computed from a set of data is an observed point estimate of \\(\\theta\\). For example, if \\(x_i\\) are the observed grade point averages of a sample of 88 students, then: \\[ \\bar{x} = \\frac{1}{88} \\sum_{i=1}^{88} x_i = 3.12 \\] is a point estimate of \\(\\mu\\), the mean grade point average of all the students in the population. And, if \\(x_i = 0\\) if a student has no tattoo, and \\(x_i = 1\\) if a student has a tattoo, then: \\[ \\hat{p} = 0.11 \\] is a point estimate of \\(p\\), the proportion of all students in the population who have a tattoo. Now, with the above definitions aside, let’s go learn about the method of maximum likelihood. 1.2 Maximum Likelihood Estimation Statement of the Problem Suppose we have a random sample \\(X_1, X_2, ..., X_n\\) whose assumed probability distribution depends on some unknown parameter \\(\\theta\\). Our primary goal here will be to find a point estimator \\(u(X_1, X_2, ..., X_n)\\), such that \\(u(x_1, x_2, ..., x_n)\\) is a “good” point estimate of \\(\\theta\\), where \\(x_1, x_2, ..., x_n\\) are the observed values of the random sample. For example, if we plan to take a random sample \\(X_1, X_2, ..., X_n\\) for which the \\(X_i\\) are assumed to be normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then our goal will be to find a good estimate of \\(\\mu\\), say, using the data \\(x_1, x_2, ..., x_n\\) that we obtained from our specific random sample. The Basic Idea It seems reasonable that a good estimate of the unknown parameter \\(\\theta\\) would be the value of \\(\\theta\\) that maximizes the probability, or rather, the likelihood, of getting the data we observed. So, that is, in a nutshell, the idea behind the method of maximum likelihood estimation. But how would we implement the method in practice? Well, suppose we have a random sample \\(X_1, X_2, ..., X_n\\) for which the probability density (or mass) function of each \\(X_i\\) is \\(f(x_i;\\theta)\\). Then, the joint probability mass (or density) function of \\(X_1, X_2, ..., X_n\\), which we’ll (not so arbitrarily) call \\(L(\\theta)\\) is: \\[L(\\theta) = P(X_1=x_1, X_2=x_2, ..., X_n=x_n) = f(x_1;\\theta) \\cdot f(x_2;\\theta) \\cdot ... \\cdot f(x_n;\\theta) = \\prod_{i=1}^n f(x_i;\\theta)\\] In light of the basic idea of maximum likelihood estimation, one reasonable way to proceed is to treat the “likelihood function” \\(L(\\theta)\\) as a function of \\(\\theta\\), and find the value of \\(\\theta\\) that maximizes it. Example 1-1 Suppose we have a random sample \\(X_1, X_2, ..., X_n\\) where: \\(X_i = 0\\) if a randomly selected student does not own a sports car, and \\(X_i = 1\\) if a randomly selected student does own a sports car. Assuming that the \\(X_i\\) are independent Bernoulli random variables with unknown parameter \\(p\\), find the maximum likelihood estimator of \\(p\\), the proportion of students who own a sports car. Answer If the \\(X_i\\) are independent Bernoulli random variables with unknown parameter \\(p\\), then the probability mass function of each \\(X_i\\) is: \\[f(x_i;\\theta) = p^{x_i} \\cdot (1-p)^{1-x_i}\\] for \\(x_i = 0\\) or 1 and \\(0 &lt; p &lt; 1\\). Therefore, the likelihood function \\(L(p)\\) is, by definition: \\[L(p) = \\prod_{i=1}^n f(x_i;\\theta) = p^{x_1} \\cdot (1-p)^{1-x_1} \\cdot p^{x_2} \\cdot (1-p)^{1-x_2} \\cdot ... \\cdot p^{x_n} \\cdot (1-p)^{1-x_n}\\] for \\(0 &lt; p &lt; 1\\). Simplifying, by summing up the exponents, we get: \\[L(p) = p^{\\sum x_i} \\cdot (1-p)^{n - \\sum x_i}\\] Now, in order to implement the method of maximum likelihood, we need to find the \\(p\\) that maximizes the likelihood \\(L(p)\\). We need to put on our calculus hats now since, in order to maximize the function, we are going to need to differentiate the likelihood function with respect to \\(p\\). In doing so, we’ll use a “trick” that often makes the differentiation a bit easier. Note that the natural logarithm is an increasing function of \\(x\\): Alt Text That is, if \\(x_1 &lt; x_2\\), then \\(f(x_1) &lt; f(x_2)\\). That means that the value of \\(p\\) that maximizes the natural logarithm of the likelihood function \\(\\ln L(p)\\) is also the value of \\(p\\) that maximizes the likelihood function \\(L(p)\\). So, the “trick” is to take the derivative of \\(\\ln L(p)\\) (with respect to \\(p\\)) rather than taking the derivative of \\(L(p)\\). Again, doing so often makes the differentiation much easier. (By the way, throughout the remainder of this course, I will use either \\(\\ln L(p)\\) or \\(\\log L(p)\\) to denote the natural logarithm of the likelihood function.) In this case, the natural logarithm of the likelihood function is: \\[ \\log L(p) = \\left( \\sum_{i=1}^{n} x_i \\right) \\log(p) + \\left( n - \\sum_{i=1}^{n} x_i \\right) \\log(1-p) \\] Now, taking the derivative of the log-likelihood, and setting it to \\(0\\), we get: \\[ \\frac{\\partial \\log L(p)}{\\partial p} = \\frac{\\sum_{i=1}^{n} x_i}{p} - \\frac{n - \\sum_{i=1}^{n} x_i}{1-p} \\] Now, multiplying through by \\(p(1-p)\\), we get: \\[ \\left( \\sum_{i=1}^{n} x_i \\right) (1-p) - (n - \\sum_{i=1}^{n} x_i) p = 0 \\] Upon distribution, we see that two of the resulting terms cancel each other out: \\[ \\sum_{i=1}^{n} x_i - p \\sum_{i=1}^{n} x_i - np + p \\sum_{i=1}^{n} x_i = 0 \\] leaving us with: \\[ \\sum_{i=1}^{n} x_i - np = 0 \\] Now, all we have to do is solve for \\(p\\). In doing so, you’ll want to make sure that you always put a hat (“^”) on the parameter, in this case, \\(p\\), to indicate it is an estimate: \\[ \\hat{p} = \\frac{\\sum_{i=1}^{n} x_i}{n} \\] or, alternatively, an estimator: \\[ \\hat{p} = \\frac{\\sum_{i=1}^{n} X_i}{n} \\] Oh, and we should technically verify that we indeed did obtain a maximum. We can do that by verifying that the second derivative of the log-likelihood with respect to \\(p\\) is negative. It is, but you might want to do the work to convince yourself! Now, with that example behind us, let us take a look at formal definitions of the terms: Likelihood Function Maximum Likelihood Estimators Maximum Likelihood Estimates Definition: Let \\(X_1, X_2, ..., X_n\\) be a random sample from a distribution that depends on one or more unknown parameters \\(\\theta_1, \\theta_2, ..., \\theta_m\\) with probability density (or mass) function \\(f(x_i; \\theta_1, \\theta_2, ..., \\theta_m)\\). Suppose that \\(\\theta_1, \\theta_2, ..., \\theta_m\\) is restricted to a given parameter space \\(\\Omega\\). Then: When regarded as a function of \\(\\theta_1, \\theta_2, ..., \\theta_m\\), the joint probability density (or mass) function of \\(X_1, X_2, ..., X_n\\): \\[ L(\\theta_1, \\theta_2, ..., \\theta_m) = \\prod_{i=1}^{n} f(x_i; \\theta_1, \\theta_2, ..., \\theta_m) \\] \\((\\theta_1, \\theta_2, ..., \\theta_m)\\) in \\(\\Omega\\) is called the likelihood function. If \\([u_1(x_1, x_2, ..., x_n), u_2(x_1, x_2, ..., x_n), ..., u_m(x_1, x_2, ..., x_n)]\\) is the m-tuple that maximizes the likelihood function, then: \\[ \\hat{\\theta}_i = u_i(X_1, X_2, ..., X_n) \\] is the maximum likelihood estimator of \\(\\theta_i\\), for \\(i = 1,2,...,m\\). The corresponding observed values of the statistics in (2), namely: \\[ [u_1(x_1, x_2, ..., x_n), u_2(x_1, x_2, ..., x_n), ..., u_m(x_1, x_2, ..., x_n)] \\] are called the maximum likelihood estimates of \\(\\theta_i\\), for \\(i = 1,2,...,m\\). Example 1-2: Suppose the weights of randomly selected American female college students are normally distributed with unknown mean \\(\\mu\\) and standard deviation \\(\\sigma\\). A random sample of 10 American female college students yielded the following weights (in pounds): 115, 122, 130, 127, 149, 160, 152, 138, 149, 180. Based on the definitions given above, identify the likelihood function and the maximum likelihood estimator of \\(\\mu\\), the mean weight of all American female college students. Using the given sample, find a maximum likelihood estimate of \\(\\mu\\) as well. Answer: The probability density function of \\(X_i\\) is: \\[ f(x_i; \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left[-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right] \\] for \\(-\\infty &lt; x &lt; \\infty\\). The parameter space is \\(\\Omega = \\{ (\\mu, \\sigma) : -\\infty &lt; \\mu &lt; \\infty \\text{ and } 0 &lt; \\sigma &lt; \\infty \\}\\). Therefore, the likelihood function is: \\[ L(\\mu, \\sigma) = \\sigma^{-n} (2\\pi)^{-\\frac{n}{2}} \\exp\\left[-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\right] \\] for \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(0 &lt; \\sigma &lt; \\infty\\). It can be shown, upon maximizing the likelihood function with respect to \\(\\mu\\), that the maximum likelihood estimator of \\(\\mu\\) is: \\[ \\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} X_i = \\bar{X} \\] Based on the given sample, a maximum likelihood estimate of \\(\\mu\\) is: \\[ \\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{1}{10} (115 + \\ldots + 180) = 142.2 \\] pounds. Note that the only difference between the formulas for the maximum likelihood estimator and the maximum likelihood estimate is that: the estimator is defined using capital letters (to denote that its value is random), and the estimate is defined using lowercase letters (to denote that its value is fixed and based on an obtained sample). Okay, so now we have the formal definitions out of the way. The first example on this page involved a joint probability mass function that depends on only one parameter, namely P, the proportion of successes. Now, let’s take a look at an example that involves a joint probability density function that depends on two parameters. Example 1-3: Let \\(X_1, X_2, ..., X_n\\) be a random sample from a normal distribution with unknown mean \\(\\mu\\) and variance \\(\\sigma^2\\). Find maximum likelihood estimators of mean \\(\\mu\\) and variance \\(\\sigma^2\\). Answer: In finding the estimators, the first thing we’ll do is write the probability density function as a function of \\(\\theta_1 = \\mu\\) and \\(\\theta_2 = \\sigma^2\\): \\[ f(x_i; \\theta_1, \\theta_2) = \\frac{1}{\\sqrt{\\theta_2} \\sqrt{2\\pi}} \\exp\\left[-\\frac{(x_i - \\theta_1)^2}{2\\theta_2}\\right] \\] for \\(-\\infty &lt; \\theta_1 &lt; \\infty\\) and \\(0 &lt; \\theta_2 &lt; \\infty\\). We do this so as not to cause confusion when taking the derivative of the likelihood with respect to \\(\\sigma^2\\). Now, that makes the likelihood function: \\[ L(\\theta_1, \\theta_2) = \\prod_{i=1}^{n} f(x_i; \\theta_1, \\theta_2) = \\theta_2^{-\\frac{n}{2}} (2\\pi)^{-\\frac{n}{2}} \\exp\\left[-\\frac{1}{2\\theta_2} \\sum_{i=1}^{n} (x_i - \\theta_1)^2 \\right] \\] and therefore the log of the likelihood function: \\[ \\log L(\\theta_1, \\theta_2) = -\\frac{n}{2} \\log \\theta_2 - \\frac{n}{2} \\log(2\\pi) - \\frac{\\sum{(x_i - \\theta_1)^2}}{2\\theta_2} \\] Now, upon taking the partial derivative of the log likelihood with respect to \\(\\theta_1\\), and setting to 0, we see that a few things cancel each other out, leaving us with: \\[ \\frac{\\partial \\log L(\\theta_1, \\theta_2)}{\\partial \\theta_1} = \\frac{-2\\sum{(x_i - \\theta_1)}(-1)}{2\\theta_2} \\stackrel{\\text{set}}{=} 0 \\] Now, multiplying through by \\(\\theta_2\\), and distributing the summation, we get: \\[ \\sum{x_i - n\\theta_1} = 0 \\] Now, solving for \\(\\theta_1\\), and putting on its hat, we have shown that the maximum likelihood estimate of \\(\\theta_1\\) is: \\[ \\hat{\\theta}_1 = \\hat{\\mu} = \\frac{\\sum{x_i}}{n} = \\bar{x} \\] Now for \\(\\theta_2\\). Taking the partial derivative of the log likelihood with respect to \\(\\theta_2\\), and setting to 0, we get: \\[ \\frac{\\partial \\log L(\\theta_1, \\theta_2)}{\\partial \\theta_2} = \\frac{-n}{2\\theta_2} + \\frac{\\sum{(x_i - \\theta_1)^2}}{2\\theta_2^2} \\stackrel{\\text{set}}{=} 0 \\] Multiplying through by \\(2\\theta_2^2\\), we get: \\[ -n\\theta_2 + \\sum{(x_i - \\theta_1)^2} = 0 \\] And, solving for \\(\\theta_2\\), and putting on its hat, we have shown that the maximum likelihood estimate of \\(\\theta_2\\) is: \\[ \\hat{\\theta}_2 = \\hat{\\sigma}^2 = \\frac{\\sum{(x_i - \\theta_1)^2}}{n} \\] (I’ll again leave it to you to verify, in each case, that the second partial derivative of the log likelihood is negative, and therefore that we did indeed find maxima.) In summary, we have shown that the maximum likelihood estimators of \\(\\mu\\) and variance \\(\\sigma^2\\) for the normal model are: \\[ \\hat{\\mu} = \\left(\\sum{X_i}\\right)/n = \\bar{X} \\] and \\[ \\hat{\\sigma}^2 = \\frac{\\sum{(X_i - \\bar{X})^2}}{n} \\] respectively. Note that the maximum likelihood estimator of \\(\\sigma^2\\) for the normal model is not the sample variance \\(S^2\\). They are, in fact, competing estimators. So how do we know which estimator we should use for \\(\\sigma^2\\)? Well, one way is to choose the estimator that is “unbiased.” Let’s go learn about unbiased estimators. "],["neyman-pearson-lemma.html", "Chapter 2 Neyman-Pearson Lemma 2.1 The Neyman Pearson Lemma", " Chapter 2 Neyman-Pearson Lemma As we learned from our work in the previous lesson, whenever we perform a hypothesis test, we should make sure that the test we are conducting has sufficient power to detect a meaningful difference from the null hypothesis. That said, how can we be sure that the T-test for a mean \\(\\mu\\) is the “most powerful” test we could use? Is there instead a K-test or a V-test or you-name-the-letter-of-the-alphabet-test that would provide us with more power? A very important result, known as the Neyman-Pearson Lemma, will reassure us that each of the tests we learned in Section 7 is the most powerful test for testing statistical hypotheses about the parameter under the assumed probability distribution. Before we can present the lemma, however, we need to: Define some notation Learn the distinction between simple and composite hypotheses Define what it means to have a best critical region of size \\(\\alpha\\) Notation If \\(X_1, X_2, ..., X_n\\) is a random sample of size \\(n\\) from a distribution with probability density (or mass) function \\(f(x; \\theta)\\), then the joint probability density (or mass) function of \\(X_1, X_2, ..., X_n\\) is denoted by the likelihood function \\(L(\\theta)\\). That is, the joint p.d.f. or p.m.f. is: \\[ L(\\theta) =L(\\theta; x_1, x_2, ... , x_n) = f(x_1;\\theta) \\times f(x_2;\\theta) \\times ... \\times f(x_n;\\theta) \\] Note that for the sake of ease, we drop the reference to the sample \\(X_1, X_2, ..., X_n\\) in using \\(L(\\theta)\\) as the notation for the likelihood function. We’ll want to keep in mind though that the likelihood \\(L(\\theta)\\) still depends on the sample data. Simple hypothesis If a random sample is taken from a distribution with parameter \\(\\theta\\), a hypothesis is said to be a simple hypothesis if the hypothesis uniquely specifies the distribution of the population from which the sample is taken. Any hypothesis that is not a simple hypothesis is called a composite hypothesis. Example 1 Suppose \\(X_1, X_2, ..., X_n\\) is a random sample from an exponential distribution with parameter \\(\\theta\\). Is the hypothesis \\(H:\\theta =3\\) a simple or a composite hypothesis? Answer: The p.d.f. of an exponential random variable is: \\[ f(x) = \\frac{1}{\\theta} e^ \\frac{-x}{\\theta} \\] for \\(x \\geq 0\\). Under the hypothesis \\(H:\\theta =3\\), the p.d.f. of an exponential random variable is: \\[ f(x) = \\frac{1}{3} e^ \\frac{-x}{3} \\] for \\(x \\geq 0\\). Because we can uniquely specify the p.d.f. under the hypothesis \\(H:\\theta = 3\\), the hypothesis is a simple hypothesis. Example 2 Suppose \\(X_1, X_2, . . . ,X_n\\) is a random sample from an exponential distribution with parameter \\(\\theta\\). Is the hypothesis \\(H: \\theta &gt;2\\) a simple or a composite hypothesis? Answer: Again, the p.d.f. of an exponential random variable is: \\[ f(x) = \\frac{1}{\\theta} e^ \\frac{-x}{\\theta} \\] for \\(x \\geq 0\\). Under the hypothesis \\(H: \\theta&gt;2\\), the p.d.f. of an exponential random variable could be: \\[ f(x) = \\frac{1}{3} e^ \\frac{-x}{3} \\] for \\(x \\geq 0\\), or it could be: \\[ f(x) = \\frac{1}{22} e^ \\frac{-x}{22} \\] for \\(x \\geq 0\\), or it could be any of an infinite number of possible exponential probability density functions. Because the p.d.f. is not uniquely specified under the hypothesis \\(H: \\theta&gt;2\\), the hypothesis is a composite hypothesis. Example 3 Suppose \\(X_1, X_2, . . . ,X_n\\) is a random sample from a normal distribution with mean \\(\\mu\\) and unknown variance \\(\\sigma^2\\). Is the hypothesis \\(H:\\mu = 12\\) a simple or a composite hypothesis? Answer: The p.d.f. of a normal random variable is: \\[ f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}\\sigma} \\exp\\left[{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\right] \\] for \\(-\\infty &lt; x &lt; \\infty\\), \\(-\\infty &lt; \\mu &lt; \\infty\\), and \\(\\sigma &gt; 0\\). Under the hypothesis \\(H:\\mu = 12\\), the p.d.f. of a normal random variable is: \\[ f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}\\sigma} \\exp\\left[{-\\frac{(x-12)^2}{2\\sigma^2}}\\right] \\] for \\(-\\infty &lt; x &lt; \\infty\\), and \\(\\sigma &gt; 0\\). In this case, the mean parameter \\(\\mu=12\\) is uniquely specified in the p.d.f., but the variance \\(\\sigma^2\\) is not. Therefore, the hypothesis \\(H:\\mu = 12\\) is a composite hypothesis. Size of \\(\\alpha\\) Consider the test of the simple null hypothesis \\(H_0:\\theta = \\theta_0\\) against the simple alternative hypothesis \\(H_A: \\theta = \\theta_a\\). Let \\(C\\) and \\(D\\) be critical regions of size \\(\\alpha\\), that is, let: \\(\\alpha = P(C;\\theta_0)\\) and \\(\\alpha = P(D;\\theta_0)\\) Then, \\(C\\) is a best critical region of size \\(\\alpha\\) if the power of the test at \\(\\theta =\\theta_a\\) is the largest among all possible hypothesis tests. More formally, \\(C\\) is the best critical region of size \\(\\alpha\\) if, for every other critical region \\(D\\) of size \\(\\alpha\\), we have: \\[P(C;\\theta_0)&gt;P(D;\\theta_0)\\] That is, \\(C\\) is the best critical region of size \\(\\alpha\\) if the power of \\(C\\) is at least as great as the power of every other critical region \\(D\\) of size \\(\\alpha\\). We say that \\(C\\) is the most powerful size \\(\\alpha\\) test. Now that we have clearly defined what we mean for a critical region C to be “best,” we’re ready to turn to the Neyman Pearson Lemma to learn what form a hypothesis test must take in order for it to be the best, that is, to be the most powerful test. 2.1 The Neyman Pearson Lemma Suppose we have a random sample \\(X_1, X_2, ..., X_n\\) from a probability distribution with parameter \\(\\theta\\). Then, if \\(C\\) is a critical region of size \\(\\alpha\\) and \\(k\\) is a constant such that: \\[ \\frac{L(\\theta_0)}{L(\\theta_1)} \\leq k \\quad \\text{inside the critical region } C \\] and: \\[ \\frac{L(\\theta_0)}{L(\\theta_1)} \\geq k \\quad \\text{outside the critical region } C \\] then \\(C\\) is the best, that is, most powerful, critical region for testing the simple null hypothesis \\(H_0:\\theta = \\theta_0\\) against the simple alternative hypothesis \\(H_A:\\theta = \\theta_a\\). Proof Well, okay, so perhaps the proof isn’t all that particularly enlightening, but perhaps if we take a look at a simple example, we’ll become more enlightened. Suppose \\(X\\) is a single observation (that’s one data point!) from a normal population with unknown mean \\(\\mu\\) and known standard deviation \\(\\sigma=1/3\\). Then, we can apply the Neyman-Pearson Lemma when testing the simple null hypothesis \\(H_0: \\mu = 3\\) against the simple alternative hypothesis \\(H_A:\\mu = 4\\). The lemma tells us that, in order to be the most powerful test, the ratio of the likelihoods: \\[ \\frac{L(\\mu_0)}{L(\\mu_\\alpha)}=\\frac{L(3)}{L(4)} \\] should be small for sample points \\(X\\) inside the critical region \\(C\\) (“less than or equal to some constant \\(k\\)”) and large for sample points \\(X\\) outside of the critical region (“greater than or equal to some constant \\(k\\)”). In this case, because we are dealing with just one observation \\(X\\), the ratio of the likelihoods equals the ratio of the normal probability curves: \\[ \\frac{L(3)}{L(4)}=\\frac{f(x; 3,1/9)}{f(x; 4,1/9)} \\] Then, the following drawing summarizes the situation: Alt text In short, it makes intuitive sense that we would want to reject \\(H_0:\\mu=3\\) in favor of \\(H_A:\\mu=4\\) if our observed \\(x\\) is large, that is, if our observed \\(x\\) falls in the critical region \\(C\\). Well, as the drawing illustrates, it is those large \\(X\\) values in \\(C\\) for which the ratio of the likelihoods is small; and, it is for the small \\(X\\) values not in \\(C\\) for which the ratio of the likelihoods is large. Just as the Neyman-Pearson Lemma suggests! Well, okay, that’s the intuition behind the Neyman-Pearson Lemma. Now, let’s take a look at a few examples of the lemma in action. Example 4 Suppose \\(X\\) is a single observation (again, one data point!) from a population with probability density function given by: \\[ f(x) = \\theta x^{\\theta-1} \\] for \\(0 &lt; x &lt; 1\\). Find the test with the best critical region, that is, find the most powerful test, with significance level \\(\\alpha =0.05,\\) for testing the simple null hypothesis \\(H_0:\\theta=3\\) against the simple alternative hypothesis \\(H_A:\\theta=2\\). Answer Because both the null and alternative hypotheses are simple hypotheses, we can apply the Neyman-Pearson Lemma in an attempt to find the most powerful test. The lemma tells us that the ratio of the likelihoods under the null and alternative must be less than some constant \\(k\\). Again, because we are dealing with just one observation \\(X\\), the ratio of the likelihoods equals the ratio of the probability density functions, giving us: \\[ \\frac{L(\\theta_0)}{L(\\theta_\\alpha)}=\\frac{3x^{3-1}}{2x^{2-1}}=\\frac{3}{2}x\\le k \\] That is, the lemma tells us that the form of the rejection region for the most powerful test is: \\[ \\frac{3}{2}x\\le k \\] or alternatively, since \\(\\frac{2}{3}k\\) is just a new constant \\(k^*\\), the rejection region for the most powerful test is of the form: \\[ x&lt;\\frac{3}{2}k= k^* \\] Now, it’s just a matter of finding \\(k^*\\), and our work is done. We want \\(\\alpha = P(\\text{Type I Error}) = P(\\text{rejecting the null hypothesis when the null hypothesis is true})\\) to equal \\(0.05\\). In order for that to happen, the following must hold: \\[ \\alpha=P(X&lt;k^* \\, when \\, \\theta=3)=\\int_{0}^{k^*}3x^2 \\, dx = 0.05 \\] Doing the integration, we get: \\[ \\left[x^3 \\right]_{x=0}^{x=k^*}=(k^*)^3 = 0.05 \\] And, solving for \\(k^*\\), we get: \\[ k^* = (0.05)^\\frac{1}{3} =0.368 \\] That is, the Neyman-Pearson Lemma tells us that the rejection region of the most powerful test for testing \\(H_0:\\theta = 3\\) against \\(H_A:\\theta = 2\\), under the assumed probability distribution, is: \\[ x &lt; 0.368 \\] That is, among all of the possible tests for testing \\(H_0:\\theta = 3\\) against \\(H_A:\\theta = 2\\), based on a single observation \\(X\\) and with a significance level of \\(0.05\\), this test has the largest possible value for the power under the alternative hypothesis, that is, when \\(\\theta = 2\\). Example 5 Suppose \\(X_1, X_2, ..., X_n\\) is a random sample from a normal population with mean \\(\\mu\\) and variance 16. Find the test with the best critical region, that is, find the most powerful test, with a sample size of \\(n = 16\\) and a significance level \\(\\alpha=0.05\\) to test the simple null hypothesis \\(H_0:\\mu = 10\\) against the simple alternative hypothesis \\(H_A:\\mu = 15\\). Answer Because the variance is specified, both the null and alternative hypotheses are simple hypotheses. Therefore, we can apply the Neyman-Pearson Lemma in an attempt to find the most powerful test. The lemma tells us that the ratio of the likelihoods under the null and alternative must be less than some constant \\(k\\): \\[ \\frac{L(10)}{L(15)} = \\frac{(32\\pi)^{-16/2}\\exp\\left[-(1/32)\\sum^{16}_{i=1}(x_i-10)^2\\right]}{(32\\pi)^{-16/2}\\exp\\left[-(1/32)\\sum^{16}_{i=1}(x_i-15)^2\\right]} \\le k \\] Simplifying, we get: \\[ exp \\left[ - \\left( \\dfrac{1}{32} \\right) \\left( \\sum_{i=1}^{16}(x_i -10)^2 - \\sum_{i=1}^{16}(x_i -15)^2 \\right) \\right] \\le k \\] And, simplifying yet more, we get: Alt text Now, taking the natural logarithm of both sides of the inequality, collecting like terms, and multiplying through by 32, we get: \\[-10\\Sigma x_i +2000 \\le 32ln(k)\\] And, moving the constant term on the left-side of the inequality to the right-side, and dividing through by −160, we get: \\[\\dfrac{1}{16}\\Sigma x_i \\ge -\\frac{1}{160}(32ln(k)-2000)\\] That is, the Neyman Pearson Lemma tells us that the rejection region for the most powerful test for testing \\(H_0:\\mu=10\\) against \\(H_A:\\mu=15\\), under the normal probability model, is of the form: \\[\\bar{x} \\ge k^*\\] where \\(k^*\\) is selected so that the size of the critical region is \\(\\alpha=0.05\\). That’s simple enough, as it just involves a normal probabilty calculation! Under the null hypothesis, the sample mean is normally distributed with mean 10 and standard deviation 4/4 = 1. Therefore, the critical value \\(k^*\\) is deemed to be 11.645: Alt text That is, the Neyman Pearson Lemma tells us that the rejection region for the most powerful test for testing \\(H_0:\\mu=10\\) against \\(H_A:\\mu=15\\), under the normal probability model, is: \\[\\bar{x}\\ge11.645\\] The power of such a test when \\(\\mu = 15\\) is: \\[P(\\bar{X} &gt; 11.645 \\text{ when } \\mu = 15) = P \\left( Z &gt; \\dfrac{11.645-15}{\\sqrt{16} / \\sqrt{16} } \\right) = P(Z &gt; -3.36) = 0.9996 \\] The power can’t get much better than that, and the Neyman Pearson Lemma tells us that we shouldn’t expect it to get better! That is, the Lemma tells us that there is no other test out there that will give us greater power for testing \\(H_0:\\mu=10\\) against \\(H_A:\\mu=15\\) "],["testing-and-estimation---large-vs.-small-samples.html", "Chapter 3 Testing and Estimation - Large vs. Small Samples 3.1 Central Limit Theorem (CLT) 3.2 Conceptual Explanation 3.3 Testing Large Samples 3.4 Estimation of Parameters 3.5 Small Sample Situations", " Chapter 3 Testing and Estimation - Large vs. Small Samples This lecture note explores the concepts of testing and estimation in the context of large and small samples. 3.1 Central Limit Theorem (CLT) The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of sample means when drawing repeated samples from a population. It states that, regardless of the shape of the population distribution, the distribution of sample means will tend to be approximately normal as the sample size increases. 3.2 Conceptual Explanation The CLT is based on three key principles: Sampling Distribution: When we draw multiple samples from a population and calculate the mean of each sample, we create a sampling distribution of the sample means. Approximate Normality: The distribution of sample means will be approximately normal if the sample size is sufficiently large, regardless of the shape of the population distribution. This is particularly true for sample sizes greater than 30. Mean and Standard Deviation: The mean of the sample means will be approximately equal to the population mean, and the standard deviation of the sample means (standard error) will decrease as the sample size increases. Example 1 Suppose we want to understand the distribution of the mean height of students in the campus of Gadau. We’ll collect the heights of 10000 students as our population data. # Simulate student heights in Gadau campus set.seed(123) student_heights &lt;- rnorm(1000, mean = 170, sd = 10) # Display summary statistics of student heights summary(student_heights) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 141.9 163.7 170.1 170.2 176.6 202.4 # Number of samples num_samples &lt;- 1000 # Sample size sample_size &lt;- 30 # Initialize a vector to store sample means sample_means &lt;- numeric(num_samples) # Take random samples and calculate means for (i in 1:num_samples) { sample &lt;- sample(student_heights, sample_size) sample_means[i] &lt;- mean(sample) } # Plot the distribution of sample means hist(sample_means, breaks = 30, main = &quot;Distribution of Sample Means&quot;, xlab = &quot;Sample Mean Height (cm)&quot;, col = &quot;lightblue&quot;, border = &quot;white&quot;) In the histogram above, we can observe that as the number of samples increases, the distribution of sample means becomes more symmetric and bell-shaped, resembling a normal distribution. This is consistent with the Central Limit Theorem. Example 2: Rolling a Fair Die Suppose we want to understand the distribution of the mean of rolling a fair six-sided die. We will simulate rolling the die 1000 times and calculate the mean for each set of rolls. # Set seed for reproducibility set.seed(123) # Simulate rolling a fair six-sided die 1000 times num_rolls &lt;- 1000 die_rolls &lt;- sample(1:6, num_rolls, replace = TRUE) # Calculate the mean of each set of rolls sample_means &lt;- numeric(num_rolls) for (i in 1:num_rolls) { sample_means[i] &lt;- mean(sample(die_rolls, i)) } # Plot the distribution of sample means hist(sample_means, breaks = 30, main = &quot;Distribution of Sample Means&quot;, xlab = &quot;Sample Mean&quot;, col = &quot;lightblue&quot;, border = &quot;white&quot;) ## Testing and Estimation of Binomial Distribution 3.2.1 Understanding the Binomial Distribution Before we proceed, let’s quickly recap what the binomial distribution entails. The binomial distribution describes the probability of a certain number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success. It is characterized by two parameters: the number of trials, denoted as \\(n\\), and the probability of success in each trial, denoted as \\(p\\). Example Scenario Dice Rolls: Rolling a regular six-sided die multiple times. The binomial distribution helps us predict how many times we might roll a specific number, like getting exactly three 6s out of ten rolls. Light Switch: Turning a light switch on and off. Each time you flip the switch, it’s like a trial where you can either get light (success) or darkness (failure). The binomial distribution helps us estimate the probability of getting a certain number of successes (light) in a series of trials. Bowling Pins: Knocking down bowling pins with a ball. Each time you roll the ball, you either knock down some pins or miss completely. The binomial distribution helps us calculate the likelihood of knocking down a certain number of pins in a given number of attempts. Basketball Shots: Shooting basketballs into a hoop. Each shot can either go in (success) or miss (failure). The binomial distribution can help us figure out the chances of making a certain number of shots out of several attempts. Example of a Binomial Distribution Suppose in a university, 70% of students pass a certain course on their first attempt. If we randomly select 20 students from the university, what is the probability that exactly 15 of them will pass the course on their first attempt? Using the binomial distribution, the probability of exactly 15 students passing the course is given by: \\[ P(X = 15) = \\binom{20}{15} (0.70)^{15} (1 - 0.70)^{20 - 15} \\] Where: Plugging in the values: \\[ P(X = 15) = \\binom{20}{15} (0.70)^{15} (0.30)^{5} \\] Calculating: \\[ P(X = 15) = \\frac{20!}{15! \\times (20 - 15)!} (0.70)^{15} (0.30)^{5} \\] \\[ P(X = 15) = \\frac{20!}{15! \\times 5!} (0.70)^{15} (0.30)^{5} \\] \\[ P(X = 15) = \\frac{20 \\times 19 \\times 18 \\times 17 \\times 16}{5 \\times 4 \\times 3 \\times 2 \\times 1} (0.70)^{15} (0.30)^{5} \\] \\[ P(X = 15) = 15504 \\times (0.70)^{15} (0.30)^{5} \\] \\[ P(X = 15) \\approx 0.1073 \\] Therefore, the probability that exactly 15 of the 20 selected students will pass the course on their first attempt is approximately 0.1073. 3.3 Testing Large Samples When dealing with large samples, we often utilize normal approximation to the binomial distribution due to the Central Limit Theorem (CLT). The CLT states that the sampling distribution of the sample mean will be approximately normally distributed for large sample sizes, regardless of the distribution of the population. 3.3.1 Z-Test for Proportions In testing large samples for binomial distributions, we typically employ the Z-test for proportions. This test allows us to determine whether the proportion of successes in our sample significantly differs from a hypothesized value. The formula for the Z-test statistic is: \\[ Z = \\frac{{\\hat{p} - p_0}}{{\\sqrt{\\frac{{p_0(1 - p_0)}}{n}}}} \\] Where: - \\(\\hat{p}\\) is the sample proportion, - \\(p_0\\) is the hypothesized proportion under the null hypothesis, and - \\(n\\) is the sample size. Binomial Testing Example Suppose in a university campus, it is believed that 60% of the students own a laptop. To test this claim, a random sample of 200 students is taken, and it is found that 115 of them own a laptop. We want to test whether the proportion of students owning a laptop is significantly different from the claimed proportion of 60%. Hypotheses Let \\(p\\) be the true proportion of students owning a laptop. The null hypothesis (\\(H_0\\)) is that \\(p = 0.60\\), and the alternative hypothesis (\\(H_1\\)) is that \\(p \\neq 0.60\\). Test Statistic We will use the Z-test for proportions to test the hypotheses. The test statistic is given by: \\[ Z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}} \\] where: Given: \\[\\begin{align*} \\hat{p} &amp;= \\frac{115}{200} = 0.575 \\\\ p_0 &amp;= 0.60 \\\\ n &amp;= 200 \\end{align*}\\] Using these values, we can calculate the test statistic: \\[ Z = \\frac{0.575 - 0.60}{\\sqrt{\\frac{0.60(1 - 0.60)}{200}}} \\] \\[ Z = \\frac{-0.025}{\\sqrt{\\frac{0.60(0.40)}{200}}} \\] \\[ Z \\approx \\frac{-0.025}{\\sqrt{\\frac{0.24}{200}}} \\] \\[ Z \\approx \\frac{-0.025}{\\sqrt{0.0012}} \\] \\[ Z \\approx \\frac{-0.025}{0.0346} \\] \\[ Z \\approx -0.7225 \\] Conclusion The calculated value of the test statistic is \\(Z = -0.7225\\). At a significance level of 0.05 (or 95% confidence level), the critical values for a two-tailed test are \\(\\pm 1.96\\). Since \\(-1.96 &lt; -0.7225 &lt; 1.96\\), we fail to reject the null hypothesis. Therefore, there is not enough evidence to conclude that the proportion of students owning a laptop is significantly different from 60%. 3.4 Estimation of Parameters 3.4.1 Point Estimation Point estimation involves estimating a single value for a population parameter based on sample data. For the binomial distribution, we often estimate the population proportion \\(p\\) using the sample proportion \\(\\hat{p}\\). 3.4.2 Interval Estimation Interval estimation, on the other hand, provides a range of values within which the population parameter is likely to lie. For large samples, the confidence interval for the population proportion can be calculated using the normal approximation: \\[ \\hat{p} \\pm Z_{\\alpha/2} \\times \\sqrt{\\frac{{\\hat{p}(1 - \\hat{p})}}{n}} \\] Where \\(Z_{\\alpha/2}\\) is the critical value from the standard normal distribution corresponding to the desired level of confidence. Example Suppose in a university campus, it is believed that 60% of the students own a laptop. To estimate the true proportion of students owning a laptop, a random sample of 200 students is taken, and it is found that 115 of them own a laptop. We want to construct a 95% confidence interval for the true proportion of students owning a laptop. Interval Estimate For large samples, the confidence interval for the population proportion can be calculated using the normal approximation: \\[ \\hat{p} \\pm Z_{\\alpha/2} \\times \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} \\] where: Given: \\[\\begin{align*} \\hat{p} &amp;= 0.575 \\\\ n &amp;= 200 \\\\ \\alpha &amp;= 0.05 \\end{align*}\\] At a 95% confidence level, \\(Z_{\\alpha/2} = 1.96\\). Plugging in the values: \\[ \\text{Margin of Error} = 1.96 \\times \\sqrt{\\frac{0.575(1 - 0.575)}{200}} \\approx 0.0704 \\] \\[ \\text{Lower Bound} = 0.575 - 0.0704 \\approx 0.5046 \\] \\[ \\text{Upper Bound} = 0.575 + 0.0704 \\approx 0.6446 \\] Therefore, the 95% confidence interval for the true proportion of students owning a laptop is approximately \\((0.5046, 0.6446)\\). 3.5 Small Sample Situations In small sample situations, the normal approximation may not be appropriate. Instead, we rely on exact methods such as the binomial test or the chi-square goodness-of-fit test. 3.5.1 Binomial Test The binomial test is used to assess whether the observed number of successes in a sample significantly differs from the expected number of successes under a specified null hypothesis. It directly calculates the probability of observing the given number of successes or more extreme outcomes. Example Suppose in a university campus, it is believed that 60% of the students own a laptop. To test this claim, a random sample of 20 students is taken, and it is found that 11 of them own a laptop. We want to test whether the proportion of students owning a laptop is significantly different from the claimed proportion of 60%. Hypotheses Let \\(p\\) be the true proportion of students owning a laptop. The null hypothesis (\\(H_0\\)) is that \\(p = 0.60\\), and the alternative hypothesis (\\(H_1\\)) is that \\(p \\neq 0.60\\). Test Statistic For small sample situations, we can use the binomial test to assess whether the observed number of successes in a sample significantly differs from the expected number of successes under the null hypothesis. The test statistic for the binomial test is the number of successes (\\(k\\)). Calculation Given: \\[\\begin{align*} k &amp;= 11 \\\\ n &amp;= 20 \\\\ p_0 &amp;= 0.60 \\end{align*}\\] Using these values, we can calculate the probability of observing 11 or fewer successes under the null hypothesis: \\[ P(X \\leq 11) = \\sum_{x=0}^{11} \\binom{20}{x} (0.60)^x (0.40)^{20-x} \\] Using statistical software or tables, we find \\(P(X \\leq 11) \\approx 0.049\\). Since \\(P(X \\leq 11) &lt; 0.05\\), we reject the null hypothesis. The observed proportion of students owning a laptop is significantly different from the claimed proportion of 60%. Binomial Testing Example Suppose in a university campus, it is believed that 60% of the students own a laptop. To test this claim, a random sample of 200 students is taken, and it is found that 115 of them own a laptop. We want to test whether the proportion of students owning a laptop is significantly different from the claimed proportion of 60%. Hypotheses Let \\(p\\) be the true proportion of students owning a laptop. The null hypothesis (\\(H_0\\)) is that \\(p = 0.60\\), and the alternative hypothesis (\\(H_1\\)) is that \\(p \\neq 0.60\\). Test Statistic We will use the Z-test for proportions to test the hypotheses. The test statistic is given by: \\[ Z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}} \\] where: Given: \\[\\begin{align*} \\hat{p} &amp;= \\frac{115}{200} = 0.575 \\\\ p_0 &amp;= 0.60 \\\\ n &amp;= 200 \\end{align*}\\] Using these values, we can calculate the test statistic: \\[ Z = \\frac{0.575 - 0.60}{\\sqrt{\\frac{0.60(1 - 0.60)}{200}}} \\] \\[ Z = \\frac{-0.025}{\\sqrt{\\frac{0.60(0.40)}{200}}} \\] \\[ Z \\approx \\frac{-0.025}{\\sqrt{\\frac{0.24}{200}}} \\] \\[ Z \\approx \\frac{-0.025}{\\sqrt{0.0012}} \\] \\[ Z \\approx \\frac{-0.025}{0.0346} \\] \\[ Z \\approx -0.7225 \\] Conclusion The calculated value of the test statistic is \\(Z = -0.7225\\). At a significance level of 0.05 (or 95% confidence level), the critical values for a two-tailed test are \\(\\pm 1.96\\). Since \\(-1.96 &lt; -0.7225 &lt; 1.96\\), we fail to reject the null hypothesis. Therefore, there is not enough evidence to conclude that the proportion of students owning a laptop is significantly different from 60%. 3.5.2 Chi-Square Goodness-of-Fit Test The chi-square goodness-of-fit test is another method for testing the fit of observed data to an expected distribution. It can be used to compare the observed frequencies in different categories with the expected frequencies. Example Suppose in a university campus, it is believed that 60% of the students own a laptop. To test this claim, a random sample of 20 students is taken, and it is found that 11 of them own a laptop. We want to test whether the proportion of students owning a laptop follows the claimed proportion of 60%. Hypotheses Let \\(p\\) be the true proportion of students owning a laptop. The null hypothesis (\\(H_0\\)) is that the observed proportions follow the claimed proportion of 60%, and the alternative hypothesis (\\(H_1\\)) is that they do not. Test Statistic For the chi-square goodness-of-fit test, we compare the observed frequencies with the expected frequencies under the null hypothesis. The test statistic is given by: \\[ \\chi^2 = \\sum \\frac{{(O_i - E_i)^2}}{{E_i}} \\] where: Given: \\[\\begin{align*} \\text{Observed successes (students with laptops)} &amp;= 11 \\\\ \\text{Total sample size} &amp;= 20 \\\\ \\text{Expected successes (based on claimed proportion)} &amp;= 0.60 \\times 20 = 12 \\end{align*}\\] Using these values, we can calculate the chi-square test statistic: \\[ \\chi^2 = \\frac{{(11 - 12)^2}}{{12}} = \\frac{{(-1)^2}}{{12}} = \\frac{1}{12} \\approx 0.0833 \\] Conclusion At a significance level of 0.05, with 1 degree of freedom, the critical value for the chi-square distribution is approximately 3.841. Since \\(\\chi^2 = 0.0833 &lt; 3.841\\), we fail to reject the null hypothesis. Therefore, we do not have enough evidence to conclude that the observed proportions significantly differ from the claimed proportion of 60%. "],["understanding-the-poisson-distribution.html", "Chapter 4 Understanding the Poisson Distribution 4.1 Testing Large Samples for Poisson Distribution 4.2 Interval Estimation for Poisson Distribution", " Chapter 4 Understanding the Poisson Distribution Before we proceed, let’s quickly recap what the Poisson distribution entails. The Poisson distribution describes the probability of a certain number of events occurring in a fixed interval of time or space. It is often used to model the number of occurrences of rare events in a large population. Example Scenarios Phone Calls: Counting the number of phone calls received by a call center in an hour. The Poisson distribution helps us predict how many calls we might receive during a specific time period, such as getting exactly five calls in an hour. Traffic Accidents: Recording the number of traffic accidents that occur at a particular intersection in a day. The Poisson distribution helps us estimate the probability of a certain number of accidents happening in a given timeframe, like having exactly two accidents in a day. Typographical Errors: Counting the number of typographical errors in a book. The Poisson distribution can help us calculate the likelihood of having a specific number of errors in a given number of pages, such as having exactly ten errors in 100 pages. Email Arrivals: Tracking the number of emails arriving in an inbox per minute. The Poisson distribution helps us understand the probability of receiving a certain number of emails in a short time span, like getting exactly three emails in a minute. Poisson Distribution Example Suppose we are interested in modeling the number of students visiting the library in an hour at the University of Gadau. Let’s assume that, on average, the library receives 10 students per hour. Probability Mass Function The Poisson distribution helps us calculate the probability of a certain number of events occurring in a fixed interval of time or space. Let’s calculate the probability of having exactly 5 students visit the library in an hour using the Poisson distribution. Given: \\[\\begin{align*} \\lambda &amp;= 10 \\quad \\text{(average number of students per hour)}, \\\\ k &amp;= 5 \\quad \\text{(number of students we&#39;re interested in)}. \\end{align*}\\] The probability mass function (PMF) of the Poisson distribution is given by: \\[ P(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!} \\] Plugging in the values: \\[ P(X = 5) = \\frac{e^{-10} \\times 10^5}{5!} \\] \\[ P(X = 5) = \\frac{e^{-10} \\times 100000}{120} \\] Calculating: \\[ P(X = 5) \\approx \\frac{0.0000454 \\times 100000}{120} \\] \\[ P(X = 5) \\approx \\frac{4.54}{120} \\] \\[ P(X = 5) \\approx 0.0378 \\] Therefore, the probability of having exactly 5 students visit the library in an hour is approximately 0.0378. Cumulative Distribution Function The cumulative distribution function (CDF) of the Poisson distribution gives the probability of having up to a certain number of events occur. Let’s calculate the probability of having up to 5 students visit the library in an hour. Given: \\[ \\lambda = 10 \\quad \\text{(average number of students per hour)}, \\\\ k = 5 \\quad \\text{(number of students we&#39;re interested in)}. \\] The cumulative distribution function (CDF) of the Poisson distribution is given by: \\[ P(X \\leq k) = \\sum_{i=0}^{k} \\frac{e^{-\\lambda} \\lambda^i}{i!} \\] Plugging in the values: \\[ P(X \\leq 5) = \\sum_{i=0}^{5} \\frac{e^{-10} \\times 10^i}{i!} \\] Calculating: \\[ P(X \\leq 5) = \\frac{e^{-10} \\times 10^0}{0!} + \\frac{e^{-10} \\times 10^1}{1!} + \\frac{e^{-10} \\times 10^2}{2!} + \\frac{e^{-10} \\times 10^3}{3!} + \\frac{e^{-10} \\times 10^4}{4!} + \\frac{e^{-10} \\times 10^5}{5!} \\] \\[ P(X \\leq 5) = e^{-10} + \\frac{10e^{-10}}{1} + \\frac{100e^{-10}}{2} + \\frac{1000e^{-10}}{6} + \\frac{10000e^{-10}}{24} + \\frac{100000e^{-10}}{120} \\] \\[ P(X \\leq 5) \\approx 0.0671 \\] Therefore, the probability of having up to 5 students visit the library in an hour is approximately 0.0671. #PMF in R lambda &lt;- 10 # Average number of students visiting the library per hour k &lt;- 5 # Number of students we&#39;re interested in # Calculate PMF for exactly 5 students pmf_5_students &lt;- dpois(k, lambda) pmf_5_students ## [1] 0.03783327 # Calculate CDF for up to 5 students cdf_up_to_5_students &lt;- ppois(k, lambda) cdf_up_to_5_students ## [1] 0.06708596 4.1 Testing Large Samples for Poisson Distribution The Poisson distribution describes the probability of a certain number of events occurring in a fixed interval of time or space. It is often used to model the number of occurrences of rare events in a large population. 4.1.1 Testing Large Samples When dealing with large samples, we can use the normal approximation to the Poisson distribution due to the Central Limit Theorem (CLT). The CLT states that the sampling distribution of the sample mean will be approximately normally distributed for large sample sizes, regardless of the distribution of the population. 4.1.2 Test Statistic The test statistic for testing large samples for the Poisson distribution is given by: \\[ Z = \\frac{\\hat{\\lambda} - \\lambda_0}{\\sqrt{\\frac{\\lambda_0}{n}}} \\] where: - \\(\\hat{\\lambda}\\) is the sample mean, - \\(\\lambda_0\\) is the hypothesized mean under the null hypothesis, - \\(n\\) is the sample size. Example Suppose we are interested in testing whether the average number of accidents at a particular intersection is different from 5 per day. We collect a large sample of accident data and find that the sample mean is \\(\\hat{\\lambda} = 6\\) accidents per day. Let’s perform the hypothesis test: Null Hypothesis (\\(H_0\\)): \\(\\lambda = \\lambda_0 = 5\\) Alternative Hypothesis (\\(H_1\\)): \\(\\lambda \\neq \\lambda_0\\) Given \\(n = 1000\\), we can use the test statistic formula to calculate the value of \\(Z\\). Given: \\[\\begin{align*} \\hat{\\lambda} &amp;= 6 \\\\ \\lambda_0 &amp;= 5 \\\\ n &amp;\\text{ is large} \\end{align*}\\] We can calculate the test statistic: \\[ Z = \\frac{{6 - 5}}{{\\sqrt{5}}} = \\frac{1}{\\sqrt{\\frac{5}{1000}}} \\] [ Z ] Conclusion Since the sample size is large, we can use the standard normal distribution to find the critical values. At a significance level of \\(\\alpha = 0.05\\), the critical values for a two-tailed test are \\(\\pm 1.96\\). Since \\(-1.96 &lt; 14.14 &lt; 1.96\\), we fail to reject the null hypothesis. Therefore, there is not enough evidence to conclude that the average number of earthquakes per month is significantly different from 5. # Define parameters lambda_hat &lt;- 6 # Sample mean lambda_0 &lt;- 5 # Hypothesized mean under null hypothesis n &lt;- 1000 # Sample size # Calculate test statistic Z &lt;- (lambda_hat - lambda_0) / sqrt(lambda_0 / n) Z ## [1] 14.14214 4.2 Interval Estimation for Poisson Distribution Suppose we have a sample from a population that follows a Poisson distribution with parameter \\(\\lambda\\). We want to construct a confidence interval for the true value of \\(\\lambda\\). Method For large samples, we can use the normal approximation to the Poisson distribution to construct a confidence interval for \\(\\lambda\\). The confidence interval is given by: \\[ \\left( \\hat{\\lambda} \\pm Z_{\\alpha/2} \\sqrt{\\frac{\\hat{\\lambda}}{n}} \\right) \\] where: Example Suppose we have a sample of earthquake occurrences in a region over a certain period of time. We want to estimate the average number of earthquakes per month, denoted by \\(\\lambda\\), using a confidence interval. Sample Information Given: \\[\\begin{align*} n &amp;= 50 \\quad \\text{(sample size)}, \\\\ \\text{Total number of earthquakes observed} &amp;= 60. \\end{align*}\\] Method To construct a confidence interval for \\(\\lambda\\), we’ll use the normal approximation to the Poisson distribution. The confidence interval is given by: \\[ \\hat{\\lambda} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{\\lambda}}{n}} \\] where: Calculation Given: \\[ \\hat{\\lambda} = \\frac{\\text{Total number of earthquakes observed}}{n} = \\frac{60}{50} = 1.2 \\] and using a 95% confidence level (\\(\\alpha = 0.05\\)), the critical value \\(z_{\\alpha/2}\\) is approximately 1.96. The margin of error is: \\[ \\text{Margin of Error} = 1.96 \\times \\sqrt{\\frac{1.2}{50}} \\approx 0.3036 \\] Confidence Interval Therefore, the 95% confidence interval for the average number of earthquakes per month is approximately: \\[ 1.2 \\pm 0.3036 = (0.8963637, 1.503636) \\] Conclusion We are 95% confident that the true average number of earthquakes per month in the region falls within the interval (0.8963637, 1.503636). # Given data total_earthquakes &lt;- 60 sample_size &lt;- 50 # Calculate sample mean lambda_hat &lt;- total_earthquakes / sample_size # Calculate standard error se &lt;- sqrt(lambda_hat / sample_size) # Critical value for 95% confidence level z &lt;- qnorm(0.975) # Calculate margin of error margin_error &lt;- z * se # Calculate confidence interval lower_bound &lt;- lambda_hat - margin_error upper_bound &lt;- lambda_hat + margin_error # Print results cat(&quot;Sample mean (lambda hat):&quot;, lambda_hat, &quot;\\n&quot;) ## Sample mean (lambda hat): 1.2 cat(&quot;Margin of error:&quot;, margin_error, &quot;\\n&quot;) ## Margin of error: 0.3036363 cat(&quot;95% Confidence interval:&quot;, lower_bound, &quot;-&quot;, upper_bound, &quot;\\n&quot;) ## 95% Confidence interval: 0.8963637 - 1.503636 "],["normal-contingency-tables.html", "Chapter 5 Normal Contingency Tables 5.1 Test of Homogeneity 5.2 Goodness-of-Fit Test", " Chapter 5 Normal Contingency Tables Contingency tables are used to summarize the relationship between two categorical variables. In a normal contingency table, the expected frequencies are calculated assuming that the variables are independent. Normal Contingency Table Calculation Suppose we have the following contingency table for two categorical variables: \\[ \\begin{array}{c|cc|c} &amp; \\text{Variable 1 (A)} &amp; \\text{Variable 1 (B)} &amp; \\text{Total} \\\\ \\hline \\text{Variable 2 (X)} &amp; a &amp; b &amp; a + b \\\\ \\text{Variable 2 (Y)} &amp; c &amp; d &amp; c + d \\\\ \\hline \\text{Total} &amp; a + c &amp; b + d &amp; n \\end{array} \\] The expected frequency for each cell under the assumption of independence between the variables can be calculated as: \\[ E_{ij} = \\frac{(a + c)(a + b)}{n}, \\quad \\text{for cell } (i, j) \\] Now, let’s calculate the expected frequencies for each cell: \\[ \\begin{array}{c|cc|c} &amp; \\text{Variable 1 (A)} &amp; \\text{Variable 1 (B)} &amp; \\text{Total} \\\\ \\hline \\text{Variable 2 (X)} &amp; \\frac{(a + c)(a + b)}{n} &amp; \\frac{(a + c)(b + d)}{n} &amp; a + b \\\\ \\text{Variable 2 (Y)} &amp; \\frac{(b + d)(a + b)}{n} &amp; \\frac{(b + d)(b + d)}{n} &amp; c + d \\\\ \\hline \\text{Total} &amp; a + c &amp; b + d &amp; n \\end{array} \\] Example Suppose we have data on the smoking habits and lung cancer incidence in a population. We want to investigate whether there is a relationship between smoking and lung cancer. \\[ \\begin{array}{|c|c|c|} \\hline &amp; \\text{Smoker} &amp; \\text{Non-Smoker} \\\\ \\hline \\text{Lung Cancer} &amp; 50 &amp; 100 \\\\ \\hline \\text{No Lung Cancer} &amp; 200 &amp; 500 \\\\ \\hline \\end{array} \\] Method To test for independence between smoking and lung cancer, we’ll calculate the expected frequencies under the assumption of independence. The expected frequency for a cell is given by: \\[ E_{ij} = \\frac{{R_i \\times C_j}}{{N}} \\] where: Calculation Given: \\[ \\begin{aligned} &amp;\\text{Total observations (N)} = 850, \\\\ &amp;\\text{Total smokers} = 250, \\\\ &amp;\\text{Total non-smokers} = 600, \\\\ &amp;\\text{Total lung cancer cases} = 250, \\\\ &amp;\\text{Total cases of no lung cancer} = 600. \\end{aligned} \\] The expected frequency for the “Smoker, Lung Cancer” cell is: \\[ E_{\\text{Smoker}, \\text{Lung Cancer}} = \\frac{{250 \\times 250}}{{850}} = 73.53 \\] Similarly, we calculate the expected frequencies for the other cells. Conclusion Once we have calculated the expected frequencies, we can compare them to the observed frequencies to test for independence between smoking and lung cancer. 5.1 Test of Homogeneity Example The head of a surgery department at a university medical center was concerned that surgical residents in training applied unnecessary blood transfusions at a different rate than the more experienced attending physicians. Therefore, he ordered a study of the 49 Attending Physicians and 71 Residents in Training with privileges at the hospital. For each of the 120 surgeons, the number of blood transfusions prescribed unnecessarily in a one-year period was recorded. Based on the number recorded, a surgeon was identified as either prescribing unnecessary blood transfusions Frequently, Occasionally, Rarely, or Never. Here’s a summary table (or “contingency table”) of the resulting data: [ \\[\\begin{array}{c|c|c|c|c|c} \\text{Physician} &amp; \\text{Frequent} &amp; \\text{Occasionally} &amp; \\text{Rarely} &amp; \\text{Never} &amp; \\text{Total} \\\\ \\hline \\text{Attending} &amp; 2 \\, (4.1\\%) &amp; 3 \\, (6.1\\%) &amp; 31 \\, (63.3\\%) &amp; 13 \\, (26.5\\%) &amp; 49 \\\\ \\text{Resident} &amp; 15 \\, (21.1\\%) &amp; 28 \\, (39.4\\%) &amp; 23 \\, (32.4\\%) &amp; 5 \\, (7.0\\%) &amp; 71 \\\\ \\hline \\text{Total} &amp; 17 &amp; 31 &amp; 54 &amp; 18 &amp; 120 \\\\ \\end{array}\\] ] We are interested in testing the null hypothesis: \\[ H_0: \\text{Attending Physicians and Residents in Training are distributed equally among the various unnecessary blood transfusion categories} \\] against the alternative hypothesis: \\[ H_1: \\text{Attending Physicians and Residents in Training are not distributed equally among the various unnecessary blood transfusion categories} \\] The observed data were given to us in the table above. So, the next thing we need to do is find the expected counts for each cell of the table. It is in the calculation of the expected values that you can readily see why we have \\((2-1)(4-1) = 3\\) degrees of freedom in this case. That’s because we only have to calculate three of the cells directly. [ \\[\\begin{array}{c|c|c|c|c|c} \\text{Physician} &amp; \\text{Frequent} &amp; \\text{Occasionally} &amp; \\text{Rarely} &amp; \\text{Never} &amp; \\text{Total} \\\\ \\hline \\text{Attending} &amp; 6.942= (\\frac{17}{120}49) &amp; 12.658=(\\frac{31}{120}49) &amp; 22.05=(\\frac{54}{120}49) &amp; - &amp; 49 \\\\ \\text{Resident} &amp; - &amp; - &amp; - &amp; - &amp; 71 \\\\ \\hline \\text{Total} &amp; 17 &amp; 31 &amp; 54 &amp; 18 &amp; 120 \\\\ \\end{array}\\] ] Once we do that, the remaining five cells can be calculated by way of subtraction: [ \\[\\begin{array}{c|c|c|c|c|c} \\text{Physician} &amp; \\text{Frequent} &amp; \\text{Occasionally} &amp; \\text{Rarely} &amp; \\text{Never} &amp; \\text{Total} \\\\ \\hline \\text{Attending} &amp; 6.942 &amp; 12.658 &amp; 22.05 &amp; 7.35 &amp; 49 \\\\ \\text{Resident} &amp; 10.058 &amp; 18.342 &amp; 31.95 &amp; 10.65 &amp; 71 \\\\ \\hline \\text{Total} &amp; 17 &amp; 31 &amp; 54 &amp; 18 &amp; 120 \\\\ \\end{array}\\] ] Now that we have the observed and expected counts, calculating the chi-square statistic is a straightforward exercise: \\[ Q = \\frac{(2-6.942)^2}{6.942} + \\frac{(3-12.658)^2}{12.658} + \\frac{(31-22.05)^2}{22.05} + \\\\ \\frac{(13-7.35)^2}{7.35} + \\frac{(15-10.058)^2}{10.058} + \\frac{(28-18.342)^2}{18.342} + \\\\ \\frac{(23-31.95)^2}{31.95} + \\frac{(5-10.65)^2}{10.65} \\] The chi-square test tells us to reject the null hypothesis, at the 0.05 level, if \\(Q\\) is greater than a chi-square random variable with 3 degrees of freedom, that is, if \\(Q &gt; \\chi^2_{0.05, 3}\\). Because \\(Q = 39.88\\), and \\(\\chi^2_{0.05, 3} = 7.815\\), we reject the null hypothesis. There is sufficient evidence at the 0.05 level to conclude that the distribution of unnecessary transfusions differs among attending physicians and residents. 5.2 Goodness-of-Fit Test The Goodness-of-Fit test is a statistical test used to determine whether an observed frequency distribution fits a theoretical distribution. It is commonly used to compare observed data with expected frequencies from a theoretical model. Hypotheses Let \\(O_i\\) denote the observed frequency for category \\(i\\), and \\(E_i\\) denote the expected frequency for category \\(i\\) under the null hypothesis. The null hypothesis (\\(H_0\\)) is that the observed frequencies fit the theoretical distribution: \\[ H_0: O_i = E_i \\text{ for all categories} \\] The alternative hypothesis (\\(H_1\\)) is that the observed frequencies do not fit the theoretical distribution: \\[ H_1: \\text{At least one } O_i \\text{ differs significantly from } E_i \\] Test Statistic The test statistic for the Goodness-of-Fit test is typically based on the Chi-square (\\(\\chi^2\\)) distribution and is calculated as follows: \\[ \\chi^2 = \\sum_{i} \\frac{(O_i - E_i)^2}{E_i} \\] where the sum is taken over all categories. Worked Example Suppose we have a six-sided die and we want to test whether it is fair. We roll the die 120 times and record the following frequencies for each face: \\[ \\begin{array}{cc} \\toprule \\text{Face} &amp; \\text{Observed Frequency} \\\\ \\midrule 1 &amp; 20 \\\\ 2 &amp; 18 \\\\ 3 &amp; 25 \\\\ 4 &amp; 22 \\\\ 5 &amp; 17 \\\\ 6 &amp; 18 \\\\ \\bottomrule \\end{array} \\] To test whether the observed frequencies fit the expected frequencies for a fair die, we calculate the expected frequency for each face. Since the die is fair, we expect each face to occur with equal probability, i.e., \\(E_i = \\frac{120}{6} = 20\\) for all faces. Now, we calculate the test statistic: \\[ \\chi^2 = \\frac{(20 - 20)^2}{20} + \\frac{(18 - 20)^2}{20} + \\frac{(25 - 20)^2}{20} + \\frac{(22 - 20)^2}{20} + \\frac{(17 - 20)^2}{20} + \\frac{(18 - 20)^2}{20} \\] \\[ = \\frac{0}{20} + \\frac{4}{20} + \\frac{25}{20} + \\frac{4}{20} + \\frac{9}{20} + \\frac{4}{20} \\] \\[ = \\frac{42}{20} = 2.1 \\] Conclusion With 5 degrees of freedom, at a significance level of 0.05, the critical value of \\(\\chi^2\\) is approximately 11.07. Since our calculated \\(\\chi^2\\) value (2.1) is less than the critical value, we fail to reject the null hypothesis. Therefore, we conclude that the observed frequencies are consistent with those expected for a fair die. Additional Example Suppose the admissions office at State University Gadau claims that the distribution of incoming students across departments is 30% in Business, 40% in Engineering, and 30% in Liberal Arts. To verify this claim, they collect data on 300 incoming students and observe the following distribution: We want to test whether the observed distribution of incoming students matches the claimed distribution. Hypotheses Test Statistic We will use the chi-square test statistic to assess the goodness of fit. The formula for the chi-square test statistic is: \\[ \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i} \\] where: Calculation Under the null hypothesis, the expected frequency of students in each department can be calculated based on the claimed distribution. Therefore, we expect: We will then calculate the chi-square test statistic using the observed and expected frequencies. \\[ \\begin{aligned} \\chi^2 &amp;= \\frac{(90 - 90)^2}{90} + \\frac{(110 - 120)^2}{120} + \\frac{(100 - 90)^2}{90} \\\\ &amp;= \\frac{0^2}{90} + \\frac{(-10)^2}{120} + \\frac{10^2}{90} \\\\ &amp;= \\frac{0}{90} + \\frac{100}{120} + \\frac{100}{90} \\\\ &amp;= \\frac{100}{120} + \\frac{100}{90} \\\\ &amp;\\approx 1.11 \\end{aligned} \\] Since the calculated chi-square value is approximately 1.11, and assuming a significance level of 0.05, we fail to reject the null hypothesis. Thus, we conclude that there is no significant difference between the observed and expected distributions of incoming students across departments, supporting the admissions office’s claim. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
